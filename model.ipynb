{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PXpf2Ga7bzekCdy2LD3RTxXN2WGR6zfL",
      "authorship_tag": "ABX9TyNUVVCEm/ssT8YJxnPGSb9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/93model/Sec4_pro_Sentiment_analysis/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "id": "U9uYkBqAkBXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmoNwLgpVE-9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "metadata": {
        "id": "a2U18HKkkF84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_moive_review_data = pd.read_table('ratings_train.txt')\n",
        "test_moive_review_data = pd.read_table('ratings_test.txt')"
      ],
      "metadata": {
        "id": "tx_zgi6ikIaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moive_review_data = pd.concat([train_moive_review_data, test_moive_review_data])\n",
        "moive_review_data = moive_review_data[['document','label']]\n",
        "\n",
        "print('전체 영화 리뷰 개수 :',len(moive_review_data)) "
      ],
      "metadata": {
        "id": "GeGyUllckz6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moive_review_data.head(5)"
      ],
      "metadata": {
        "id": "UgOnU39ivNWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")\n",
        "shop_data = pd.read_table('ratings_total.txt', names=['ratings', 'document'])\n",
        "print('전체  쇼핑 리뷰 개수 :',len(shop_data)) "
      ],
      "metadata": {
        "id": "--wNaNo3juE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_data['label'] = np.select([shop_data.ratings > 3], [1], default=0)\n",
        "shop_data = shop_data[['document','label']]\n",
        "shop_data.head(5)\n"
      ],
      "metadata": {
        "id": "RV6EJ1iKl-1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/steam.txt\", filename=\"sratings_total.txt\")\n",
        "steam_data = pd.read_table('ratings_total.txt', names=['label', 'document'])\n",
        "steam_data = steam_data[['document','label']]\n",
        "steam_data.head(5)\n"
      ],
      "metadata": {
        "id": "VcWWZCS2mIRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 스팀 리뷰 개수 :',len(steam_data)) "
      ],
      "metadata": {
        "id": "neyVgUpnfZ-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1QAP3yznHDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_val = pandas.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/감성대화말뭉치(원시데이터)_Validation.csv\")\n",
        "comu_train =  pandas.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/감성대화말뭉치(최종데이터)_Training.csv\")\n"
      ],
      "metadata": {
        "id": "OLg7M8dsncLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_data = pd.concat([comu_val,comu_train])\n",
        "comu_data = comu_data[['감정_대분류','시스템응답1']]\n",
        "print('전체 감정 응답 리뷰 개수 :',len(comu_data)) "
      ],
      "metadata": {
        "id": "F1rttgbVms1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_data['감정_대분류'].unique()"
      ],
      "metadata": {
        "id": "jKr4G5yBtMJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_data.isnull().sum()"
      ],
      "metadata": {
        "id": "zIxMGBzIk92f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_data['감정_대분류'].value_counts()\n"
      ],
      "metadata": {
        "id": "C0y6-eB1kz3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "change_value_dict = {'불안': 0, '기쁨': 1, '분노':0, '슬픔':0, '상처':0, '당황': None, '불안 ':0, '기쁨 ':1, 'nan' : None}\n",
        "comu_data = comu_data.replace({'감정_대분류': change_value_dict})\n",
        "comu_data['감정_대분류'].unique()"
      ],
      "metadata": {
        "id": "JZKBKEwStdMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_data.columns = ['label','document']\n",
        "comu_data = comu_data[['document','label']]"
      ],
      "metadata": {
        "id": "u4AiSxi7vU56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comu_data.isnull().sum()"
      ],
      "metadata": {
        "id": "yQDBw8bZkMDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([moive_review_data ,shop_data,steam_data,comu_data])\n",
        "all_data.info()"
      ],
      "metadata": {
        "id": "_pQKAan4v1ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리\n"
      ],
      "metadata": {
        "id": "o9IlyqZQwmU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 제거\n",
        "all_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "all_data.info()"
      ],
      "metadata": {
        "id": "QToT_5Z2woDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 검사 \n",
        "all_data.isnull().values.any()"
      ],
      "metadata": {
        "id": "6GZd65TBxByM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 제거\n",
        "all_data = all_data.dropna()\n",
        "all_data.info()"
      ],
      "metadata": {
        "id": "RBGP3if8xL2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.isnull().values.any()"
      ],
      "metadata": {
        "id": "DEIso2LDxTx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터 분리\n"
      ],
      "metadata": {
        "id": "CnplJ0LH2w9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "id": "7w2oe-OV3Fbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2)\n",
        "print('훈련용 리뷰의 개수 :', len(train_data))\n",
        "print('테스트용 리뷰의 개수 :', len(test_data))"
      ],
      "metadata": {
        "id": "xo_Amed1xTmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['label'].value_counts().plot(kind = 'bar')\n",
        "print(train_data.groupby('label').size().reset_index(name = 'count'))"
      ],
      "metadata": {
        "id": "elCyAcBu4Cxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글과 공백을 제외하고 모두 제거\n",
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data['document'].replace('', np.nan, inplace=True)\n",
        "train_data = train_data.dropna(how='any') # Null 값 제거\n",
        "print('전처리 후 훈련용 샘플의 개수 :',len(train_data))"
      ],
      "metadata": {
        "id": "Pw4RDsgf5LGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.drop_duplicates(subset = ['document'], inplace=True) # 중복 제거\n",
        "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ],
      "metadata": {
        "id": "nUl6jpuO5cPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        " \n",
        "## Save pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/train_data.pickle\",\"wb\") as fw:\n",
        "    pickle.dump(train_data, fw)\n",
        "\n",
        "    \n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/test_data.pickle\",\"wb\") as fw:\n",
        "    pickle.dump(train_data, fw)"
      ],
      "metadata": {
        "id": "IR5BjvAIN7lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# konlpy 사용\n",
        "# 불용어 작성\n",
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "Tii8YpUL7DrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HmTO3E4gN5aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train = [] \n",
        "t_test = []\n",
        "for sentence in train['document']:\n",
        "    temp_X = okt.morphs(sentence, stem = True) \n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    t_train.append(temp_X)\n",
        "    \n",
        "for sentence in test['document']:\n",
        "    temp_X = okt.morphs(sentence, stem = True) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    t_test.append(temp_X)"
      ],
      "metadata": {
        "id": "RHApxpnA8lmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(t_train)\n",
        "tokenizer.fit_on_texts(t_test)"
      ],
      "metadata": {
        "id": "IzMWUsvKKMTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_path = 'drive/MyDrive/'"
      ],
      "metadata": {
        "id": "RhhQcODINL4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "id": "8OyYK5A2NWwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        " \n",
        "## Save pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/all_data_tok.pickle\",\"wb\") as fw:\n",
        "    pickle.dump(tokenizer, fw)"
      ],
      "metadata": {
        "id": "HWuDZiqWKPOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pickle5"
      ],
      "metadata": {
        "id": "u0-43UNvLHMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 1\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt) * 100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq) * 100)"
      ],
      "metadata": {
        "id": "9Jkt8-hQOTL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = total_cnt - rare_cnt + 1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "metadata": {
        "id": "7hJi9ioEPyrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tokenizer.texts_to_sequences(t_train)\n",
        "X_test = tokenizer.texts_to_sequences(t_test)"
      ],
      "metadata": {
        "id": "rlL4NoIYOb9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train['label']\n",
        "y_test = test['label']"
      ],
      "metadata": {
        "id": "AxmOAHZQOgj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('문장의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('문장의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeIH6_GTOjSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\n",
        " \n",
        " \n",
        "max_len = 47\n",
        "below_threshold_len(max_len,X_train)"
      ],
      "metadata": {
        "id": "3vcZXfLqOmgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "metadata": {
        "id": "sgpnDWLEOxeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "LHBCv9U6Ozx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nXkUs0MQnBIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(LSTM(128, return_sequences = True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train , epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "nUd6OP1_O1D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "XBGwvBsqQ_bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(LSTM(128, return_sequences = True))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/lstm_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train , epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "IZgYD25RnCR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = load_model('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/lstm_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (lstm_model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "yzrYnwNcnKeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/gru_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train , epochs=5, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "Rug6VowMop1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = load_model('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/gru_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (gru_model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "EYYB40m_oRXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(LSTM(128, return_sequences = True))\n",
        "model.add(GRU(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/lstm_gru_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train , epochs=5, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "ieWJRAe9oLYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model = load_model('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/lstm_gru_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (lstm_gru_model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "h700gu62o7pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(LSTM(128, return_sequences = True))\n",
        "model.add(GRU(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/lstm_gru_drop_out_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train , epochs=5, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "t6MdmUrpo_MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_drop_out_model = load_model('/content/drive/MyDrive/Colab Notebooks/CS_AI_10/Sc4/Sc4_project/lstm_gru_drop_out_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (lstm_gru_drop_out_model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "DXSzNPpMpOWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
        "  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
        "  score = float(loaded_model.predict(pad_new)) # 예측\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 문장입니다.\\n\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 문장입니다.\\n\".format((1 - score) * 100))"
      ],
      "metadata": {
        "id": "DyIXDpRLQ4oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('멍청이')"
      ],
      "metadata": {
        "id": "oA32XtF7Q5fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('사실 내가 런던에 8박 9일이라는 긴 일정을 잡은 이유는 뮤지컬 때문이다. 뉴욕에서 라이온 킹 단 한 편만 봤다는 게 너무나도 한이 되어서 런던에서 뮤지컬을 제대로 보기로 다짐했다. 그런데 매일 저녁 런던의 모든 극장에서 뮤지컬이 펼쳐지지만, 뮤지컬 좌석은 엄청 비싸다. 그나마 배우들의 얼굴이 보이 는 1층 자리는 적어도 최소 100파운드(15만 원)부터 시작하며 중 앙에 가깝고 앞으로 갈수록 비싸진다. 하지만, 나 같은 가난한 여 행객을 위해 평일 아침 일찍 극장에 줄을 서면, 약 10파운드 정도 의 가격에 맨 앞 좌석이나, 저렴한 좌석을 얻을 수 있는 데이 시트 (Day Seat) 라는 제도가 있다.')"
      ],
      "metadata": {
        "id": "va8LUZ5EWCZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('나는 오늘 데이트를 할 예정이라 기분이 좋다.')"
      ],
      "metadata": {
        "id": "D1aHGgIXsK91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('제작사 놈들 돈 많이 벌면서 게임 이따위로 만든다.')"
      ],
      "metadata": {
        "id": "bpmQMS8Hsg1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('고기가 너무 딱딱하고 조금 탓어요')"
      ],
      "metadata": {
        "id": "kB0oGQEZsmGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('마동석은 멋있는데 영화는 재미가 없어요')"
      ],
      "metadata": {
        "id": "NE7ysPvusr4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('내 남자한테 연락하지 마라')"
      ],
      "metadata": {
        "id": "TaNw9nm3tHlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JpJbTux6tMmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('이번에 나온 시험은 망했다')"
      ],
      "metadata": {
        "id": "scc3ev3OV-F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 트럼프 조사 예정 기사( https://www.fnnews.com/news/202206130918083308)\n",
        "sentiment_predict('미 의사당 폭동에 대해 조사하고있는 하원 1.6조사위원회는 12일(현지시간) 역사상 유례가 없는 전직 대통령 도널드 트럼프에 대한 기소에 필요한 증거들이 충분히 발견되었다고 발표했다.AP통신과 미국 매체들에 따르면 하원 조사위원회는 2020년 대선 결과를 뒤집기 위해 트럼프 전 대통령이 사용한 갖가지 수법들이 법무부가 형사범으로 기소하기에 충분한 양이라고 밝혔다. 하원조사위는 트럼프의 선대본부장이었던 빌 스테피언도 13일 증인으로 소환되어 선거를 도둑 맞았다는 트럼프의 가짜 주장에 대해서 주로 진술하게 될 것이라고 말했다. 스테피언은 공개 청문회 증인으로 이미 소환장을 받았다. 9일(현지시간) 본격적으로 시작된 이번 청문회의 쟁점은 도널드 트럼프 전 대통령의 개입 여부이다. 특위는 의사당 폭동이 사실상 트럼프 전 대통령이 주도한 쿠데타 시도였다는 점을 부각하는데 주력했다.청문회 직전 조 바이든 대통령은 \"명백한 헌법 위반\"이라고 거세게 비판한 가운데, 트럼프 전 대통령은 \"미국 역사상 가장 위대한 행동이었다\"고 강조하며 정면 충돌했다. 뉴욕타임스(NYT) 등에 따르면 9일 오후 8시(한국시간 10일 오전 9시) 미 하원 1.6 조사 특별위원회의 공개 청문회가 황금시간대에 열리면서, CNN·NBC·ABC·CBS 등 대부분의 방송사가 특별 편성으로 이를 2시간여 동안 생중계했다.위원회는 앞으로 남은 청문회 일정에서도 트럼프와 측근들이 가짜 뉴스를 퍼뜨리고 법무부를 압박해 트럼프의 거짓 주장을 수용하도록 하고 심지어 당시 펜스 부통령에게까지 선거인단을 거부하게 만든 사실 등을 모두 폭로할 예정이다.트럼프 선대본부장이었던 스테피엔은 현재 와이오밍주 공화당 프라이머리의 트럼프가 추천하는 하원의원 후보 해리엣 해그먼의 캠프에서 선거총책을 맡고 있다. 트럼프 대변인 테일러 부도위치는 스테피언을 소환한 위원회의 결정은 순전히 정치적인 동기에서 나온 것이라고 비난했다.')"
      ],
      "metadata": {
        "id": "xzwoQ7t_XAW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}